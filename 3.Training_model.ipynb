{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train_train\n",
    "%store -r y_train_train\n",
    "%store -r X_train_test\n",
    "%store -r y_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X_train_train,X_train_test,y_train_train,y_train_test):\n",
    "    # creating a RF classifier\n",
    "    clf = RandomForestClassifier(n_estimators = 100,n_jobs=-1)\n",
    "     \n",
    "    # Training the model on the training dataset\n",
    "    # fit function is used to train the model using the training sets as parameters\n",
    "    clf.fit(X_train_train, y_train_train)\n",
    "     \n",
    "    # performing predictions on the test dataset\n",
    "    y_pred_RF = clf.predict(X_train_test)\n",
    "    \n",
    "    # using metrics module for accuracy calculation\n",
    "    print(\"\\nRF accuracy score:\\n\")\n",
    "    print(metrics.accuracy_score(y_train_test, y_pred_RF))\n",
    "    return y_pred_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_model(X_train_train,X_train_test,y_train_train,y_train_test):\n",
    "    \n",
    "    # creating http://localhost:8888/notebooks/Application_of_bigdata_pj/Project%20part%201.ipynb#a RF classifier\n",
    "    clf2 = GradientBoostingClassifier(n_estimators = 100) \n",
    "    \n",
    "    # Training the model on the training dataset\n",
    "    # fit function is used to train the model using the training sets as parameters\n",
    "    clf2.fit(X_train_train, y_train_train)\n",
    "\n",
    "    # performing predictions on the test dataset\n",
    "    y_pred_GB = clf2.predict(X_train_test)\n",
    "    \n",
    "    #using metrics module for accuracy calculation\n",
    "    print(\"\\nGB accuracy score:\\n\")\n",
    "    print(metrics.accuracy_score(y_train_test, y_pred_GB))\n",
    "    return y_pred_GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBC_model(X_train_train,X_train_test,y_train_train,y_train_test,learning_rate,max_depth,scale_pos_weight):\n",
    "    if float(learning_rate) is None:\n",
    "        learning_rate = 0.1\n",
    "    else:\n",
    "        learning_rate = float(learning_rate)\n",
    "\n",
    "    # Set default values if no l1_ratio is provided\n",
    "    if int(max_depth) is None:\n",
    "        max_depth = 20\n",
    "    else:\n",
    "        max_depth = int(max_depth)\n",
    "            # Set default values if no l1_ratio is provided\n",
    "    if float(scale_pos_weight) is None:\n",
    "        scale_pos_weight = 0.30\n",
    "    else:\n",
    "        scale_pos_weight = float(scale_pos_weight)\n",
    "        \n",
    "    def eval_metrics(actual, pred):\n",
    "        acc = accuracy_score(actual, pred)\n",
    "        return acc\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        xg_clf = XGBClassifier(learning_rate=learning_rate, max_depth=max_depth, scale_pos_weight=scale_pos_weight,eval_metric='mlogloss',n_jobs=-1,use_label_encoder=False)\n",
    "        xg_clf.fit(X_train_train,y_train_train)    \n",
    "        \n",
    "        #print(\"\\nXGBC accuracy score:\\n\")\n",
    "        preds = xg_clf.predict(X_train_test)\n",
    "        (acc) = eval_metrics(y_train_test, preds)\n",
    "        accu = metrics.accuracy_score(y_train_test, preds)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "        mlflow.log_metric(\"Accu\", acc)\n",
    "        print(\" \\nXGBOOST accuracy score:\\n %s\" % acc)\n",
    "\n",
    "        mlflow.sklearn.log_model(xg_clf, \"model\")\n",
    "        return xg_clf, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction GB model for value 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RF accuracy score:\n",
      "\n",
      "0.9171212121212121\n",
      "\n",
      "GB accuracy score:\n",
      "\n",
      "0.9185959595959596\n",
      " \n",
      "XGBOOST accuracy score:\n",
      " 0.9186363636363636\n"
     ]
    }
   ],
   "source": [
    "y_pred_RF = RF_model(X_train_train,X_train_test,y_train_train,y_train_test)\n",
    "y_pred_GB = GB_model(X_train_train,X_train_test,y_train_train,y_train_test)\n",
    "xg_clf, preds = XGBC_model(X_train_train,X_train_test,y_train_train,y_train_test,0.1,35,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Random forest for value 95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_RF[95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction GB for value 0 to 150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_GB[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction XGBOOST for value 150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(preds[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'xg_clf' (XGBClassifier)\n"
     ]
    }
   ],
   "source": [
    "%store xg_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
