{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280a744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce886a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    #load file\n",
    "    df_train=pd.read_csv(\"application_train.csv\")\n",
    "    df_test=pd.read_csv(\"application_test.csv\")\n",
    "    \n",
    "    #set categories\n",
    "    df_train[\"CODE_GENDER\"] = df_train[\"CODE_GENDER\"].astype('category').cat.codes\n",
    "    df_test[\"CODE_GENDER\"] = df_test[\"CODE_GENDER\"].astype('category').cat.codes\n",
    "    \n",
    "    df_test['NAME_CONTRACT_TYPE']=df_test[\"NAME_CONTRACT_TYPE\"].astype('category').cat.codes\n",
    "    df_train['NAME_CONTRACT_TYPE']= df_train[\"NAME_CONTRACT_TYPE\"].astype('category').cat.codes\n",
    "    \n",
    "    df_train['FLAG_OWN_CAR']=df_train[\"FLAG_OWN_CAR\"].astype('category').cat.codes\n",
    "    df_test['FLAG_OWN_CAR']=df_test[\"FLAG_OWN_CAR\"].astype('category').cat.codes\n",
    "    \n",
    "    df_test['FLAG_OWN_REALTY']=df_test[\"FLAG_OWN_REALTY\"].astype('category').cat.codes\n",
    "    df_train['FLAG_OWN_REALTY']= df_train[\"FLAG_OWN_REALTY\"].astype('category').cat.codes\n",
    "    \n",
    "    df_train['NAME_TYPE_SUITE']=df_train[\"NAME_TYPE_SUITE\"].astype('category').cat.codes                                                                  \n",
    "    df_test['NAME_TYPE_SUITE']= df_test[\"NAME_TYPE_SUITE\"].astype('category').cat.codes\n",
    "    \n",
    "    df_test['NAME_EDUCATION_TYPE']= df_test[\"NAME_EDUCATION_TYPE\"].astype('category').cat.codes                                                          \n",
    "    df_train['NAME_EDUCATION_TYPE']= df_train[\"NAME_EDUCATION_TYPE\"].astype('category').cat.codes\n",
    "    \n",
    "    df_test['NAME_FAMILY_STATUS']= df_test[\"NAME_FAMILY_STATUS\"].astype('category').cat.codes\n",
    "    df_train['NAME_FAMILY_STATUS']= df_train[\"NAME_FAMILY_STATUS\"].astype('category').cat.codes\n",
    "                                                                     \n",
    "    df_test['NAME_HOUSING_TYPE']=df_test[\"NAME_HOUSING_TYPE\"].astype('category').cat.codes\n",
    "    df_train['NAME_HOUSING_TYPE']=df_train[\"NAME_HOUSING_TYPE\"].astype('category').cat.codes\n",
    "                                                              \n",
    "    df_test['OCCUPATION_TYPE']=df_test[\"OCCUPATION_TYPE\"].astype('category').cat.codes\n",
    "    df_train['OCCUPATION_TYPE']= df_train[\"OCCUPATION_TYPE\"].astype('category').cat.codes\n",
    "    \n",
    "    #prep for display nan / none\n",
    "    column_with_nan_df_train = df_train.columns[df_train.isnull().any()]\n",
    "    column_with_nan_df_test = df_test.columns[df_test.isnull().any()]\n",
    "    \n",
    "    #display nan / none in test / train\n",
    "    print(\"Number of null / column :\")\n",
    "    for column in column_with_nan_df_test:\n",
    "        print(column, df_test[column].isnull().sum())\n",
    "    \n",
    "    for column in column_with_nan_df_train:\n",
    "        print(column, df_train[column].isnull().sum())\n",
    "        \n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a76ec1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrice_corr(df_train,df_test):\n",
    "    #prepare correlation matrix\n",
    "    correlations = df_train.corr()['TARGET'].sort_values()\n",
    "    print('\\nMost Positive Correlations: \\n', correlations.tail(10))\n",
    "    print('\\nMost Negative Correlations: \\n', correlations.head(5),'\\n')\n",
    "    df_train_corr = df_train[['TARGET','DAYS_BIRTH','REGION_RATING_CLIENT_W_CITY','REGION_RATING_CLIENT',\n",
    "                          'DAYS_LAST_PHONE_CHANGE','FLOORSMAX_AVG','DAYS_EMPLOYED','EXT_SOURCE_1', \n",
    "                          'EXT_SOURCE_2', 'EXT_SOURCE_3',\"NAME_EDUCATION_TYPE\",\"CODE_GENDER\",\"DAYS_ID_PUBLISH\"]]\n",
    "    # Calculate correlations\n",
    "    corr = df_train_corr.corr()\n",
    "    # Heatmap\n",
    "    plt.figure(figsize=(15,8))\n",
    "    sns.heatmap(corr, annot=True, linewidths=.2, cmap=\"YlGnBu\")\n",
    "    print(\"\\nCorrelation matrix :\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a28fe",
   "metadata": {},
   "source": [
    "we choose the values with the most correlation, and we delete the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1998e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_train(df_train,df_test):\n",
    "    X_train = df_train[['DAYS_BIRTH','REGION_RATING_CLIENT_W_CITY','REGION_RATING_CLIENT','DAYS_LAST_PHONE_CHANGE',\"NAME_EDUCATION_TYPE\",\"CODE_GENDER\",\"DAYS_ID_PUBLISH\"]]\n",
    "    Y_train = df_train[\"TARGET\"]\n",
    "    \n",
    "    #Unused\n",
    "    X_test = df_test[['DAYS_BIRTH','REGION_RATING_CLIENT_W_CITY','REGION_RATING_CLIENT','DAYS_LAST_PHONE_CHANGE',\"NAME_EDUCATION_TYPE\",\"CODE_GENDER\",\"DAYS_ID_PUBLISH\"]]\n",
    "    \n",
    "    X_train=X_train.dropna()\n",
    "    \n",
    "    X_train = X_train[:300000]\n",
    "    Y_train = Y_train[:300000]\n",
    "    \n",
    "    X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train, Y_train, test_size=0.33, random_state=42)\n",
    "    \n",
    "    return X_train_train, X_train_test, y_train_train, y_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59618224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X_train_train,X_train_test,y_train_train,y_train_test):\n",
    "    # creating a RF classifier\n",
    "    clf = RandomForestClassifier(n_estimators = 100,verbose=1,n_jobs=-1)\n",
    "     \n",
    "    # Training the model on the training dataset\n",
    "    # fit function is used to train the model using the training sets as parameters\n",
    "    clf.fit(X_train_train, y_train_train)\n",
    "     \n",
    "    # performing predictions on the test dataset\n",
    "    y_pred_train = clf.predict(X_train_test)\n",
    "    \n",
    "    # using metrics module for accuracy calculation\n",
    "    print(\"\\nRF accuracy score:\\n\")\n",
    "    print(metrics.accuracy_score(y_train_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b827485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_model(X_train_train,X_train_test,y_train_train,y_train_test):\n",
    "    # creating http://localhost:8888/notebooks/Application_of_bigdata_pj/Project%20part%201.ipynb#a RF classifier\n",
    "    clf2 = GradientBoostingClassifier(n_estimators = 1000,verbose=1) \n",
    "     \n",
    "    # Training the model on the training dataset\n",
    "    # fit function is used to train the model using the training sets as parameters\n",
    "    clf2.fit(X_train_train, y_train_train)\n",
    "     \n",
    "    # performing predictions on the test dataset\n",
    "    y_pred_train = clf2.predict(X_train_test)\n",
    "     \n",
    "    #using metrics module for accuracy calculation\n",
    "    print(\"\\nGB accuracy score:\\n\")\n",
    "    print(metrics.accuracy_score(y_train_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fd92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBC_model(X_train_train,X_train_test,y_train_train,y_train_test):\n",
    "    xg_clf = XGBClassifier(learning_rate=0.1, max_depth=20, scale_pos_weight=0.30,eval_metric='mlogloss',n_jobs=-1,use_label_encoder=False,verbosity =1)\n",
    "    xg_clf.fit(X_train_train,y_train_train)    \n",
    "    preds = xg_clf.predict(X_train_test)\n",
    "    print(\"\\nXGBC accuracy score:\\n\")\n",
    "    print(metrics.accuracy_score(y_train_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae1b95",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_train,df_test = init()\n",
    "    matrice_corr(df_train,df_test)\n",
    "    X_train_train,X_train_test,y_train_train,y_train_test = setup_train(df_train,df_test)\n",
    "    RF_model(X_train_train,X_train_test,y_train_train,y_train_test)\n",
    "    GB_model(X_train_train,X_train_test,y_train_train,y_train_test)\n",
    "    XGBC_model(X_train_train,X_train_test,y_train_train,y_train_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
