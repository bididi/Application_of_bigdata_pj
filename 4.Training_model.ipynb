{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d75b98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce53411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train_train\n",
    "%store -r y_train_train\n",
    "%store -r X_train_test\n",
    "%store -r y_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd77ebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X_train_train,X_train_test,y_train_train,y_train_test):\n",
    "    # creating a RF classifier\n",
    "    clf = RandomForestClassifier(n_estimators = 100,n_jobs=-1)\n",
    "     \n",
    "    # Training the model on the training dataset\n",
    "    # fit function is used to train the model using the training sets as parameters\n",
    "    clf.fit(X_train_train, y_train_train)\n",
    "     \n",
    "    # performing predictions on the test dataset\n",
    "    y_pred_train = clf.predict(X_train_test)\n",
    "    \n",
    "    # using metrics module for accuracy calculation\n",
    "    print(\"\\nRF accuracy score:\\n\")\n",
    "    print(metrics.accuracy_score(y_train_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "927f1b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GB_model(X_train_train,X_train_test,y_train_train,y_train_test):\n",
    "    \n",
    "    # creating http://localhost:8888/notebooks/Application_of_bigdata_pj/Project%20part%201.ipynb#a RF classifier\n",
    "    clf2 = GradientBoostingClassifier(n_estimators = 100) \n",
    "    \n",
    "    # Training the model on the training dataset\n",
    "    # fit function is used to train the model using the training sets as parameters\n",
    "    clf2.fit(X_train_train, y_train_train)\n",
    "\n",
    "    # performing predictions on the test dataset\n",
    "    y_pred_train = clf2.predict(X_train_test)\n",
    "    \n",
    "    #using metrics module for accuracy calculation\n",
    "    print(\"\\nGB accuracy score:\\n\")\n",
    "    print(metrics.accuracy_score(y_train_test, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ebeb7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def XGBC_model(X_train_train,X_train_test,y_train_train,y_train_test,learning_rate,max_depth,scale_pos_weight):\n",
    "    if float(learning_rate) is None:\n",
    "        learning_rate = 0.1\n",
    "    else:\n",
    "        learning_rate = float(learning_rate)\n",
    "\n",
    "    # Set default values if no l1_ratio is provided\n",
    "    if int(max_depth) is None:\n",
    "        max_depth = 20\n",
    "    else:\n",
    "        max_depth = int(max_depth)\n",
    "            # Set default values if no l1_ratio is provided\n",
    "    if float(scale_pos_weight) is None:\n",
    "        scale_pos_weight = 0.30\n",
    "    else:\n",
    "        scale_pos_weight = float(scale_pos_weight)\n",
    "        \n",
    "    def eval_metrics(actual, pred):\n",
    "        acc = accuracy_score(actual, pred)\n",
    "        return acc\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        xg_clf = XGBClassifier(learning_rate=learning_rate, max_depth=max_depth, scale_pos_weight=scale_pos_weight,eval_metric='mlogloss',n_jobs=-1,use_label_encoder=False)\n",
    "        xg_clf.fit(X_train_train,y_train_train)    \n",
    "        predict = xg_clf.predict(X_train_test)\n",
    "        \n",
    "        #print(\"\\nXGBC accuracy score:\\n\")\n",
    "        preds = xg_clf.predict(X_train_test)\n",
    "        (acc) = eval_metrics(y_train_test, preds)\n",
    "        accu = metrics.accuracy_score(y_train_test, preds)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"scale_pos_weight\", scale_pos_weight)\n",
    "        mlflow.log_metric(\"Accu\", acc)\n",
    "        print(\"  Accuracy: %s\" % acc)\n",
    "\n",
    "        mlflow.sklearn.log_model(xg_clf, \"model\")\n",
    "        return xg_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ce0f25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GB accuracy score:\n",
      "\n",
      "0.9186060606060606\n"
     ]
    }
   ],
   "source": [
    "RF_model(X_train_train,X_train_test,y_train_train,y_train_test)\n",
    "GB_model(X_train_train,X_train_test,y_train_train,y_train_test)\n",
    "xg_clf = XGBC_model(X_train_train,X_train_test,y_train_train,y_train_test,0.1,35,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b782b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'xg_clf' (XGBClassifier)\n"
     ]
    }
   ],
   "source": [
    "%store xg_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93778cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BCF",
   "language": "python",
   "name": "bcf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
