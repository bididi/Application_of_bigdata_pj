
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Welcome to Application of big data’s documentation! &#8212; Application of big data 0.1 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="welcome-to-application-of-big-data-s-documentation">
<h1>Welcome to Application of big data’s documentation!<a class="headerlink" href="#welcome-to-application-of-big-data-s-documentation" title="Permalink to this headline">¶</a></h1>
<p><strong>Application of bigdata</strong> (/Our project/) is a python project, that train us to
apply tools and concepts seen in course.  It pulls data from the
<cite>DataSet ofHome Credit Risk Classification &lt;https://www.kaggle.com/c/home-credit-default-risk/overview&gt;</cite>.</p>
<p>To run our program correctly, you will need to run the different python scripts in the following order :</p>
<blockquote>
<div><ol class="arabic simple">
<li><p>Cleaning_Dataset.ipynb</p></li>
<li><p>Features_Engineering.ipynb</p></li>
<li><p>Training_model.ipynb</p></li>
<li><p>Shap.ipynb</p></li>
</ol>
</div></blockquote>
<section id="part-1">
<h2>Part 1 :<a class="headerlink" href="#part-1" title="Permalink to this headline">¶</a></h2>
<p>In the first part, we build a machine learning project using jupyter notebook, github, a conda envirenement and sphinx.
We tried to separate the different workflow into different scripts, one for the data preparation,
one for the data preparation, one for the feature engineering, one for the models training and a
last one for the prediction.</p>
<p><strong>Data preparation</strong> :</p>
<p>We first clean the dataset from all the NAN values.</p>
<ul class="simple">
<li><p><strong>init()</strong>, will return the cleaned dataset</p></li>
</ul>
<p><strong>Feature engineering</strong> :</p>
<p>We have done a correlation matrix, and from that we have kept the most correlacted features and deleted the least correlated ones.</p>
<p>Here is the correlation matrix :</p>
<figure class="align-center">
<img alt="Image à rajouter" src="_images/matrice_de_corr.png" />
</figure>
<ul class="simple">
<li><p><strong>matrice_corr(df_train,df_test)</strong>, is a void function that show us the correlation matrix</p></li>
<li><p><strong>setup_train(df_train,df_test)</strong>, will return four values (X_train, X_test, y_train and y_test)</p></li>
</ul>
<p><strong>Models training and predict</strong> :</p>
<p>We had to train three models: XGboost, Random Forest and Gradient Boosting.
The XGboost model, is done with the optimized distributed gradient boosting library, XGboost.
The Ramdom Forest model, consists of many decision trees.
The Gradient Boosting model, is an ensemble of weak prediction models(decision trees).</p>
<ul class="simple">
<li><p><strong>XGBC_model(X_train,X_test,y_train,y_test,learning_rate,max_depth,scale_pos_weight)</strong></p></li>
<li><p><strong>RF_model(X_train,X_test,y_train,y_test)</strong></p></li>
<li><p><strong>GB_model(X_train,X_test,y_train,y_test)</strong></p></li>
</ul>
<p>Those functions train the different models.</p>
<p>All three model, succeed in predicting if a client could get a loan. Most had each around 0.91 of accuracy.</p>
<figure class="align-center">
<img alt="Image à rajouter" src="_images/capture_accu.png" />
</figure>
</section>
<section id="part-2">
<h2>Part 2 :<a class="headerlink" href="#part-2" title="Permalink to this headline">¶</a></h2>
<p>In this part, we got introduced to MLFLOW. We decided to track the parameters of the XGboost model.
It helped us to choose the best parameter, to have better result, with our model.</p>
<p>Here we can have a look at MLFlow:</p>
<figure class="align-center">
<img alt="Image à rajouter" src="_images/unknown.png" />
</figure>
</section>
<section id="part-3">
<h2>Part 3 :<a class="headerlink" href="#part-3" title="Permalink to this headline">¶</a></h2>
<p>Finaly, we used SHAP Library on our XGboost model to understand it.
We can visualize three graph by running the following function.</p>
<p>The first one is to visualize the explainations for a specific value,
we choose to select the 100th value, and we observed that the day of the last time the person changed his phone had a lot of influence on the
result of the prediction.</p>
<p>The second, is a the same as the one just seen but for all the values of the dataset. We can see the day of birth is the most influent between all the features.</p>
<p>The last one, is a summary plot for each class of the dataset.</p>
<p>Here is the graph for a specific value :</p>
<figure class="align-center">
<img alt="Texte alternatif" src="_images/shap_1.png" />
</figure>
<p>Here is the graph for all values :</p>
<figure class="align-center">
<img alt="Texte alternatif" src="_images/shap_2.png" />
</figure>
<p>Here a summary plot for each class on the whole dataset :</p>
<figure class="align-center">
<img alt="Texte alternatif" src="_images/shap_3.png" />
</figure>
<ul class="simple">
<li><p><strong>get_explainer(xg_clf,X_train_test)</strong>, is a void function that print the three graphs</p></li>
</ul>
<div class="toctree-wrapper compound">
</div>
</section>
</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this headline">¶</a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="#">Application of big data</a></h1>








<h3>Navigation</h3>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="#">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2021, Vianney.G Louis.G Elodie.G.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.2.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/index.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>